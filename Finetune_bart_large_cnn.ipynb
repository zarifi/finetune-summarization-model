{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPeS+t43CkpEKlTa9r6UM9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHjOU5Nxfd8g"
      },
      "outputs": [],
      "source": [
        "%pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "DdqMomXUfoJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": \"data/train.jsonl\", \"validation\": \"data/val.jsonl\"})\n",
        "\n",
        "# Tokenization\n",
        "def tokenize(batch):\n",
        "    inputs = tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=1024)\n",
        "    targets = tokenizer(batch[\"summary\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)"
      ],
      "metadata": {
        "id": "91ed_NgQf22U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bart-html-finetuned\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=2,\n",
        "    fp16=True  # if using GPU with mixed precision\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "c6wffo-zf4b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "rjjZsSq-gKHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"The OWASP Top 10 for LLM Applications 2025 outlines major risks...\"\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "summary_ids = model.generate(inputs[\"input_ids\"], max_length=512, min_length=50, do_sample=False)\n",
        "\n",
        "html_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(html_summary)"
      ],
      "metadata": {
        "id": "Quqe-ZTPgQL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}